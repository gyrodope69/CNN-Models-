{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, BatchNormalization, Activation, Concatenate, GlobalAveragePooling2D, Dense, Dropout, LSTM, Reshape\n",
    "\n",
    "# Define the input shape\n",
    "input_shape = (None, None, 3) # Change this according to your data\n",
    "\n",
    "# Define the input layer\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "# Apply 1x16 convolutional layer stride 1 with depth of 64\n",
    "conv1 = Conv2D(filters=64, kernel_size=(1, 16), strides=1, padding='same')(input_layer)\n",
    "\n",
    "# Apply 3x3 convolutional layer stride 1\n",
    "conv2 = Conv2D(filters=64, kernel_size=(3, 3), strides=1, padding='same')(conv1)\n",
    "\n",
    "# Apply this output to 4 different layers parallely of size 1x3, 3x1, 1x5, 5x1\n",
    "conv3_1 = Conv2D(filters=64, kernel_size=(1, 3), strides=1, padding='same')(conv2)\n",
    "conv3_2 = Conv2D(filters=64, kernel_size=(3, 1), strides=1, padding='same')(conv2)\n",
    "conv3_3 = Conv2D(filters=64, kernel_size=(1, 5), strides=1, padding='same')(conv2)\n",
    "conv3_4 = Conv2D(filters=64, kernel_size=(5, 1), strides=1, padding='same')(conv2)\n",
    "\n",
    "# Add all four output from this\n",
    "conv4 = Concatenate()([conv3_1, conv3_2, conv3_3, conv3_4])\n",
    "\n",
    "# Apply maxpool then batchnormalisation then relu\n",
    "conv5 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "conv6 = BatchNormalization()(conv5)\n",
    "conv7 = Activation('relu')(conv6)\n",
    "\n",
    "# Apply 1x7 convolution depth 64 and 7x1 convolutional layer stride1 depth 64 then batch normalization then softmax\n",
    "conv8 = Conv2D(filters=64, kernel_size=(1, 7), strides=1, padding='same')(conv7)\n",
    "conv9 = Conv2D(filters=64, kernel_size=(7, 1), strides=1, padding='same')(conv8)\n",
    "conv10 = BatchNormalization()(conv9)\n",
    "conv11 = Activation('softmax')(conv10)\n",
    "\n",
    "# Apply 5x1 convolutional layer stride1 then 3x1 convolutional layer stride1 then 5x1 convolutional layer stride1 then 3x1 convolutional layer stride\n",
    "conv12 = Conv2D(filters=64, kernel_size=(5, 1), strides=1)(conv11)\n",
    "conv13 = Conv2D(filters=64, kernel_size=(3, 1), strides=1)(conv12)\n",
    "conv14 = Conv2D(filters=64, kernel_size=(5, 1), strides=1)(conv13)\n",
    "conv15 = Conv2D(filters=64, kernel_size=(3, 1), strides=1)(conv14)\n",
    "\n",
    "# Flatten it apply global average pool then do depth wise convolution flatten in feed to fc1 and then put dropout 0.2 then apply fc2 then again dropout 0.2 then again fc3\n",
    "\n",
    "# Remove the Reshape layer before the conv2d_49 layer\n",
    "# reshape = Reshape((-1))(conv15)\n",
    "\n",
    "dw_conv = Conv2D(filters=64, kernel_size=(3, 3), strides=1)(conv15)\n",
    "dw_flat = GlobalAveragePooling2D()(dw_conv)\n",
    "\n",
    "# Add LSTM layer\n",
    "dw_flat = GlobalAveragePooling2D()(dw_conv)\n",
    "dw_reshaped = Reshape((1, 64))(dw_flat)  \n",
    "lstm_layer = LSTM(units=64)(dw_reshaped)\n",
    "\n",
    "fc1 = Dense(units=128)(lstm_layer)\n",
    "drop1 = Dropout(rate=0.2)(fc1)\n",
    "fc2 = Dense(units=64)(drop1)\n",
    "drop2 = Dropout(rate=0.2)(fc2)\n",
    "fc3 = Dense(units=10)(drop2) # Change this according to your number of classes\n",
    "\n",
    "# Define the output layer\n",
    "output_layer = Activation('softmax')(fc3)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "model.save(\"Sept2.h5\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
